{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline_GLM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RqSmeozEfTc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "385167fb-99d9-4947-9692-accbb0005a8a"
      },
      "source": [
        "# when changing riders, do a factory reset and give the folder key inside file list\n",
        "!pip install -U -q PyDrive\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# choose a local (colab) directory to store the data.\n",
        "local_download_path = os.path.expanduser('~/data')\n",
        "try:\n",
        "  os.makedirs(local_download_path)\n",
        "except: pass\n",
        "\n",
        "# 2. Auto-iterate using the query syntax\n",
        "#    https://developers.google.com/drive/v2/web/search-parameters\n",
        "file_list = drive.ListFile(\n",
        "    {'q': \"'1HdRVZ5uOwQW7XlpOyqT43YP94BsYfMv0' in parents and trashed = False and mimeType != 'application/vnd.google-apps.folder'\"}).GetList() #import swd files\n",
        "\n",
        "for f in file_list:\n",
        "  # 3. Create & download by id.\n",
        "  print('title: %s, id: %s' % (f['title'], f['id']))\n",
        "  fname = os.path.join(local_download_path, f['title'])\n",
        "  print('downloading to {}'.format(fname))\n",
        "  f_ = drive.CreateFile({'id': f['id']})\n",
        "  f_.GetContentFile(fname)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: rider4_ride2_raw.csv, id: 1vwGV4GpzSeu_RxMUVu6Aro-DVeCeGwq2\n",
            "downloading to /root/data/rider4_ride2_raw.csv\n",
            "title: rider4_ride9_raw.csv, id: 1MEU4LoBvFwowNcRhdJ32WOzzNMMdbOxC\n",
            "downloading to /root/data/rider4_ride9_raw.csv\n",
            "title: rider4_ride8_raw.csv, id: 1TFh4oVK_8sY7TlWpR-bzImARBnZdqeO-\n",
            "downloading to /root/data/rider4_ride8_raw.csv\n",
            "title: rider4_ride7_raw.csv, id: 1ICWGr_CUIQk8aeDAZ-w7byabfKROe4yy\n",
            "downloading to /root/data/rider4_ride7_raw.csv\n",
            "title: rider4_ride6_raw.csv, id: 1fq4JE7NbxRxYIaw3P6UwNg-Prr97I3Rx\n",
            "downloading to /root/data/rider4_ride6_raw.csv\n",
            "title: rider4_ride5_raw.csv, id: 1ctam-j3FoX2Ik_QLG7qNZJKtlO5E7zvN\n",
            "downloading to /root/data/rider4_ride5_raw.csv\n",
            "title: rider4_ride4_raw.csv, id: 1DGDsrJTKiVRWA4B2uNm4Jmhlvgre4r3T\n",
            "downloading to /root/data/rider4_ride4_raw.csv\n",
            "title: rider4_ride3_raw.csv, id: 1mf7mduKtuFRCDCzeLg9V32Ci0qudUFGq\n",
            "downloading to /root/data/rider4_ride3_raw.csv\n",
            "title: rider4_ride1_raw.csv, id: 1LM6Ukc48cibw-7qTOACoQcBWYPo1vrud\n",
            "downloading to /root/data/rider4_ride1_raw.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xz6THmXOEUMs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a5d8073d-e725-44d2-9c3b-96e9549622d2"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import dates as mdate\n",
        "import numpy as np\n",
        "import math\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from scipy import stats\n",
        "\n",
        "#import fbprophet\n",
        "import seaborn as seabornInstance \n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn import linear_model \n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import metrics\n",
        "from sklearn import preprocessing\n",
        "from sklearn import svm\n",
        "from sklearn.kernel_approximation import Nystroem"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzPDCECam04C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61c3ec18-8071-454d-80ff-fbd5c42aef15"
      },
      "source": [
        "# this to be run only when all data\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import glob \n",
        "import copy\n",
        "#tf.compat.v1.enable_eager_execution() \n",
        "\n",
        "mpl.rcParams['figure.figsize'] = (8, 6)\n",
        "mpl.rcParams['axes.grid'] = False\n",
        "\n",
        "#read csv all data, rename the old files with _old\n",
        "#all_files = glob.glob(\"//root//data//*raw.csv\")\n",
        "#test_files = glob.glob(\"//root//data//*old.csv\")\n",
        "\n",
        "#read csv rider wise, rename the test file as test_ and keep the rider files as is\n",
        "all_files = glob.glob(\"//root//data//rider*.csv\")\n",
        "test_files = glob.glob(\"//root//data//test*.csv\") # rename a file for testing as test_ in root/data or root/data2\n",
        "\n",
        "li=[]\n",
        "for filename in all_files:\n",
        "    print('importing...',filename)\n",
        "    df1 = pd.read_csv(filename, index_col=None, header=0)\n",
        "    print('before drop',len(df1))\n",
        "    df1.replace(r\"^\\s*$\",np.nan,inplace=True, regex=True)\n",
        "    df1.replace(r\"^\\s*true$\",1,inplace=True, regex=True)\n",
        "    df1.replace(r\"^\\s*false$\",0,inplace=True, regex=True)\n",
        "    df1.dropna(axis=0,how='any',inplace=True)\n",
        "    print('after drop',len(df1))\n",
        "    li.append(df1)\n",
        "\n",
        "df = pd.concat(li, axis=0, ignore_index=True)\n",
        "total_trn = len(df)\n",
        "print('total_train',len(df))\n",
        "\n",
        "li1=[]\n",
        "for filename in test_files:\n",
        "  print('importing...',filename)\n",
        "  df1=pd.read_csv(filename, index_col=None, header=0)\n",
        "  #df1[['cadence','altitude_smooth','grade_smooth','velocity_smooth','watts']].str.strip()\n",
        "  print('before drop1',len(df1))\n",
        "  df1.replace(r\"^\\s*$\",np.nan,inplace=True, regex=True)\n",
        "  df1.replace(r\"^\\s*true$\",1,inplace=True, regex=True)\n",
        "  df1.replace(r\"^\\s*false$\",0,inplace=True, regex=True)\n",
        "  #df1.replace(\"\",np.NaN,inplace=True)\n",
        "  #print(df1['watts'].head())\n",
        "  df1.dropna(axis=0,how='any',inplace=True)\n",
        "  #df1.to_csv('new3182519785_dropped.csv')\n",
        "  #files.download('new3182519785_dropped.csv')\n",
        "  print('after drop1',len(df1))\n",
        "  li1.append(df1)\n",
        "\n",
        "test_df = pd.concat(li1, axis=0, ignore_index=True)\n",
        "test_df_copy = copy.deepcopy(test_df)\n",
        "#test_df=test_df.dropna()\n",
        "total_tst = len(test_df)\n",
        "print('total_test',total_tst)\n",
        "#print(test_df['watts'].empty())\n",
        "#test_df_filtered = test_df[test_df['watts'].str.strip()!=np.NaN]\n",
        "print(test_df.tail())\n",
        "#df1 = pd.read_csv('_5.csv')\n",
        "#df=df.append(df1, ignore_index=True)\n",
        "\n",
        "\n",
        "#df=df[['timestamp(s)', 'position_lat(semicircles)', 'position_long(semicircles)', 'gps_accuracy(m)', 'altitude(m)',\n",
        "#       'grade(%)', 'distance(m)', 'cadence(rpm)', 'speed(m/s)', 'power(watts)', 'left_right_balance', 'temperature(C)', 'acceleration']]\n",
        "\n",
        "print (test_df.isnull().any())\n",
        "print(test_df.columns)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "importing... //root//data/rider4_ride6_raw.csv\n",
            "before drop 7195\n",
            "after drop 7195\n",
            "importing... //root//data/rider4_ride5_raw.csv\n",
            "before drop 8649\n",
            "after drop 8649\n",
            "importing... //root//data/rider4_ride7_raw.csv\n",
            "before drop 8203\n",
            "after drop 8203\n",
            "importing... //root//data/rider4_ride9_raw.csv\n",
            "before drop 14124\n",
            "after drop 14124\n",
            "importing... //root//data/rider4_ride8_raw.csv\n",
            "before drop 7284\n",
            "after drop 7284\n",
            "importing... //root//data/rider4_ride1_raw.csv\n",
            "before drop 4245\n",
            "after drop 4245\n",
            "importing... //root//data/rider4_ride4_raw.csv\n",
            "before drop 8939\n",
            "after drop 8939\n",
            "importing... //root//data/rider4_ride3_raw.csv\n",
            "before drop 14204\n",
            "after drop 14204\n",
            "total_train 72843\n",
            "importing... //root//data/test_rider4_ride2_raw.csv\n",
            "before drop1 7402\n",
            "after drop1 7402\n",
            "total_test 7402\n",
            "      Unnamed: 0      timestamp(s)  ...  accel_sensor(m2/s)  accel_gps(m2/s)\n",
            "7397        7397  26-06-2019 13.37  ...                1.65        -0.285552\n",
            "7398        7398  26-06-2019 13.37  ...               -1.85        -0.687410\n",
            "7399        7399  26-06-2019 13.37  ...                1.89        -0.433748\n",
            "7400        7400  26-06-2019 13.37  ...               -3.97        -1.017403\n",
            "7401        7401  26-06-2019 13.37  ...                1.90        -1.588802\n",
            "\n",
            "[5 rows x 32 columns]\n",
            "Unnamed: 0                    False\n",
            "timestamp(s)                  False\n",
            "position_lat(semicircles)     False\n",
            "position_long(semicircles)    False\n",
            "gps_accuracy(m)               False\n",
            "altitude(m)                   False\n",
            "grade(%)                      False\n",
            "distance(m)                   False\n",
            "cadence(rpm)                  False\n",
            "speed(m/s)                    False\n",
            "left_right_balance            False\n",
            "temperature(C)                False\n",
            "watts                         False\n",
            "acceleration                  False\n",
            "position_lat(degrees)         False\n",
            "position_long(degrees)        False\n",
            "distance_calc(m)              False\n",
            "gps_delta(m)                  False\n",
            "weight_bike_rider_50          False\n",
            "weight_bike_rider_60          False\n",
            "weight_bike_rider_70          False\n",
            "weight_bike_rider_80          False\n",
            "weight_bike_rider_90          False\n",
            "weight_bike_rider_100         False\n",
            "weight_bike_rider_110         False\n",
            "weight_bike_rider_120         False\n",
            "speed_from_sensor(m/s)        False\n",
            "speed_from_gps(m/s)           False\n",
            "wind_resistance_sensor(N)     False\n",
            "wind_resistance_gps(N)        False\n",
            "accel_sensor(m2/s)            False\n",
            "accel_gps(m2/s)               False\n",
            "dtype: bool\n",
            "Index(['Unnamed: 0', 'timestamp(s)', 'position_lat(semicircles)',\n",
            "       'position_long(semicircles)', 'gps_accuracy(m)', 'altitude(m)',\n",
            "       'grade(%)', 'distance(m)', 'cadence(rpm)', 'speed(m/s)',\n",
            "       'left_right_balance', 'temperature(C)', 'watts', 'acceleration',\n",
            "       'position_lat(degrees)', 'position_long(degrees)', 'distance_calc(m)',\n",
            "       'gps_delta(m)', 'weight_bike_rider_50', 'weight_bike_rider_60',\n",
            "       'weight_bike_rider_70', 'weight_bike_rider_80', 'weight_bike_rider_90',\n",
            "       'weight_bike_rider_100', 'weight_bike_rider_110',\n",
            "       'weight_bike_rider_120', 'speed_from_sensor(m/s)',\n",
            "       'speed_from_gps(m/s)', 'wind_resistance_sensor(N)',\n",
            "       'wind_resistance_gps(N)', 'accel_sensor(m2/s)', 'accel_gps(m2/s)'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2heBArWm78R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "2c0dcb25-d3bd-4de4-a526-9de164ea87fa"
      },
      "source": [
        "\n",
        "\n",
        "#minimal and extended feature headers. if you normalize and then use the data, remove weight from features, because it is a column of constants and will break the model.\n",
        "\n",
        "# for all files, make sure you have the same no. of cols in old and new and in same order\n",
        "\n",
        "header_sensor_minimal_new = ['distance','speed_from_sensor(m/s)','accel_sensor(m2/s)','grade_smooth','weight_bike_rider_80','watts']#'weight_bike_rider_80',\n",
        "header_gps_minimal_new = ['distance_calc(m)','speed_from_gps(m/s)','accel_gps(m2/s)','grade_smooth','watts']#'weight_bike_rider_80',\n",
        "\n",
        "header_sensor_extended_new = ['distance','speed_from_sensor(m/s)','accel_sensor(m2/s)','grade_smooth','wind_resistance_sensor(N)',\n",
        "                              'temp','cadence','altitude','watts']#'weight_bike_rider_80','heartrate',\n",
        "header_gps_extended_new = ['distance_calc(m)','speed_from_gps(m/s)','accel_gps(m2/s)','grade_smooth','wind_resistance_gps(N)',\n",
        "                           'temp','cadence','altitude','watts']#'weight_bike_rider_80','heartrate',\n",
        "header_sensor_minimal_old = ['distance(m)','speed(m/s)','accel_sensor(m2/s)','grade(%)','watts' ] #,'weight_bike_rider_80'\n",
        "header_gps_minimal_old = ['distance_calc(m)','speed_from_gps(m/s)','accel_gps(m2/s)','grade(%)', 'watts' ]#,'weight_bike_rider_80'\n",
        "\n",
        "header_sensor_extended_old = ['distance(m)','speed(m/s)','accel_sensor(m2/s)','grade(%)','wind_resistance_sensor(N)',\n",
        "                              'temperature(C)','cadence(rpm)','altitude(m)','watts']#'weight_bike_rider_80',\n",
        "header_gps_extended_old = ['distance_calc(m)','speed_from_gps(m/s)','accel_gps(m2/s)','grade(%)','wind_resistance_gps(N)',\n",
        "                           'temperature(C)','cadence(rpm)','altitude(m)','watts']#'weight_bike_rider_80',\n",
        "\n",
        "features_considered = header_sensor_minimal_old # change header here to switch between min and extended, if riderwise then put the same header, if all files put new, then old\n",
        "\n",
        "features = df[features_considered]\n",
        "\n",
        "print(features.head())\n",
        "\n",
        "test_features_considered = header_sensor_minimal_old # change header here to switch between min and extended, if riderwise then put the same header, if all files put new, then old\n",
        "\n",
        "\n",
        "test_features=test_df[test_features_considered]\n",
        "test_features.columns=features_considered \n",
        "\n",
        "print(test_features.tail())\n",
        "\n",
        "frames = [features,test_features] \n",
        "features = pd.concat(frames)  \n",
        "features[features_considered] = features[features_considered].astype(float) \n",
        "\n",
        "# below code to be uncommented on for all data\n",
        "\n",
        "#index1 = total_trn - 7943  # switch on when all files - last fle of rider 3\n",
        "#index2 = total_trn + 7195  # switch on when all files - first file of rider 4\n",
        "#train1 = features.iloc[:index1,:] # switch on when all files\n",
        "#test = features.iloc[index1:index2, :] # switch on when all files\n",
        "#train2 = features.iloc[index2:,:]# switch on when all files\n",
        "#frames2 = [train1,train2,test] # switch on when all files - used when all data\n",
        "#features = pd.concat(frames2)  # switch on when all files - used when all data\n",
        "#total_tst = len(test)\n",
        "#print(total_tst)\n",
        "\n",
        "\n",
        "print(features.head())\n",
        "print(features.tail())\n",
        "print('total dataset',len(features))\n",
        "\n",
        "\n",
        "#print(features[~features.applymap(np.isreal).all(1)])\n",
        "#plotting individual graphs for features\n",
        "#features.plot(subplots=True)\n",
        "#plt.legend(loc=1)\n",
        "#plt.savefig('features_plot.png')\n",
        "#files.download(\"features_plot.png\") \n",
        "\n",
        "#plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   distance(m)  speed(m/s)  accel_sensor(m2/s)  grade(%)  watts\n",
            "0         0.00       8.907        0.000000e+00       0.0    0.0\n",
            "1        11.32       8.846        2.830000e+00       0.0    0.0\n",
            "2        19.70       8.765        2.720000e+00       0.0    0.0\n",
            "3        28.08       8.684        0.000000e+00       0.0    0.0\n",
            "4        36.46       8.603        3.550000e-15       0.0    0.0\n",
            "      distance(m)  speed(m/s)  accel_sensor(m2/s)  grade(%)  watts\n",
            "7397     65127.96      11.644                1.65     -2.21    1.0\n",
            "7398     65138.61      11.153               -1.85     -2.65    0.0\n",
            "7399     65151.15      10.702                1.89     -2.85    0.0\n",
            "7400     65159.72       9.574               -3.97     -2.70    0.0\n",
            "7401     65170.19       8.372                1.90     -2.12    0.0\n",
            "   distance(m)  speed(m/s)  accel_sensor(m2/s)  grade(%)  watts\n",
            "0         0.00       8.907        0.000000e+00       0.0    0.0\n",
            "1        11.32       8.846        2.830000e+00       0.0    0.0\n",
            "2        19.70       8.765        2.720000e+00       0.0    0.0\n",
            "3        28.08       8.684        0.000000e+00       0.0    0.0\n",
            "4        36.46       8.603        3.550000e-15       0.0    0.0\n",
            "      distance(m)  speed(m/s)  accel_sensor(m2/s)  grade(%)  watts\n",
            "7397     65127.96      11.644                1.65     -2.21    1.0\n",
            "7398     65138.61      11.153               -1.85     -2.65    0.0\n",
            "7399     65151.15      10.702                1.89     -2.85    0.0\n",
            "7400     65159.72       9.574               -3.97     -2.70    0.0\n",
            "7401     65170.19       8.372                1.90     -2.12    0.0\n",
            "total dataset 80245\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRlQwIbUFfAj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "bbdd192e-e1ad-41fe-e726-6a496d2158e8"
      },
      "source": [
        "#runs at all times to get the results\n",
        "#please re-run the block above this block before you run this block, otherwise it will fail with an nd-array has no values error\n",
        "\n",
        "#train_split = len(train1)+len(train2) # uncomment only when all files are used.\n",
        "train_split=total_trn # uncomment when rider wise data is used\n",
        "\n",
        "#data normalization\n",
        "\n",
        "features=features.values.astype('float')  #turn on when u want to normalize ( do not use for GLM)\n",
        "data_mean=features[:train_split].mean(axis=0)  #turn on when u want to normalize ( do not use for GLM)\n",
        "data_std=features[:train_split].std(axis=0)  #turn on when u want to normalize ( do not use for GLM)\n",
        "\n",
        "data_min=features[:train_split].min(axis=0)  #turn on when u want to normalize ( do not use for GLM)\n",
        "print('data_mean', data_mean, 'data_std',data_std)  #turn on when u want to normalize ( do not use for GLM)\n",
        "features=(features-data_mean)/data_std  #turn on when u want to normalize ( do not use for GLM)\n",
        "\n",
        "features_train = features[:train_split] #used when data normalized\n",
        "fetures_test = features[train_split:] #used when data normalized, if minimal use [:,:4], if extended use [:,:8] \n",
        "X_train = features_train[:,:4].astype('float') #used when data normalized\n",
        "#print(X_train[0])\n",
        "X_test = fetures_test[:,:4].astype('float') #used when data normalized, if minimal use [:,:4], if extended use [:,:8] \n",
        "y_train = features_train[:,-1].astype('float') #used when data normalized\n",
        "y_test = fetures_test[:,-1].astype('float') #used when data normalized\n",
        "y_test=(y_test*data_std[-1]+data_mean[-1])\n",
        "\n",
        "\n",
        "#uncomment when non-normalized data is to be used\n",
        "'''features_train = features[:train_split] #used when data is non-normalized\n",
        "fetures_test = features[train_split:] #used when data is non-normalized\n",
        "X_train = features_train.iloc[:,:4].values.astype('float') #used when data is non-normalized, if minimal use [:,:4], if extended use [:,:8] \n",
        "#print(X_train[0])\n",
        "X_test = fetures_test.iloc[:,:4].values.astype('float') #used when data is non-normalized, if minimal use [:,:4], if extended use [:,:8] \n",
        "y_train = features_train.iloc[:,-1].values.astype('float') #used when data is non-normalized\n",
        "y_test = fetures_test.iloc[:,-1].values.astype('float') #used when data is non-normalized\n",
        "y_watts_calc = fetures_test.iloc[:,-2].values.astype('float')'''\n",
        "\n",
        "\n",
        "\n",
        "#use with riders 1 to 3 and uncomment when you have uncommented the data normalization above. Keep commented when data is non-normalized\n",
        "#y_watts_calc=y_watts_calc*data_std[-2]+data_mean[-2]\n",
        "#print(y_train[0])\n",
        "\n",
        "\n",
        "\n",
        "#print(len(features_train),len(fetures_test))\n",
        "y_pred_svr=[]\n",
        "y_pred_glm=[]\n",
        "y_pred_linear=[]\n",
        "y_pred_lasso=[]\n",
        "print('mean y_test',np.mean(y_test))\n",
        "\n",
        "model=['liner','lasso','svr']#, 'GLM'] #remove 'GLM' from this list if data is normalized, else keep 'GLM'\n",
        "for type in model:\n",
        "  if type == 'svr':\n",
        "    regressor=svm.SVR(kernel='rbf', C=1, gamma='auto', degree=5, epsilon=.1,coef0=1,  tol=1)\n",
        "    '''\n",
        "    regressor = linear_model.SGDRegressor()\n",
        "    feature_map_nystroem = Nystroem(gamma = .2, random_state = 1, n_components = 2000)\n",
        "    X_train_transformed = feature_map_nystroem.fit_transform(X_train)\n",
        "    X_test_transformed = feature_map_nystroem.fit_transform(X_test)\n",
        "    regressor.fit(X_train_transformed, y_train)\n",
        "    y_pred = regressor.predict(X_test_transformed)\n",
        "    '''\n",
        "    regressor.fit(X_train,y_train)\n",
        "    y_pred = regressor.predict(X_test)\n",
        "\n",
        "    print(y_test)\n",
        "    #y_pred=y_pred*data_std[-1]+data_mean[-1] #uncomment when normalized\n",
        "\n",
        "    print('Root Mean Squared Error (SVR Regression):', metrics.mean_squared_error(y_test,y_pred,squared=False))\n",
        "    print('Mean Abs Error (SVR Regression):', metrics.mean_absolute_error(y_test,y_pred))\n",
        "\n",
        "    print('R2 Score (SVR):',metrics.r2_score(y_test,y_pred))\n",
        "\n",
        "    print('mean y_pred (svr)', np.mean((y_pred)))\n",
        "    y_pred_svr=y_pred\n",
        "    #print(len(y_pred))\n",
        "    continue\n",
        "\n",
        "  if type=='liner':\n",
        "    regressor = LinearRegression()  \n",
        "    regressor.fit(X_train, y_train)\n",
        "    y_pred = regressor.predict(X_test)\n",
        "    #y_pred=y_pred*data_std[-1]+data_mean[-1] #uncomment when data is normalized\n",
        "    print('Root Mean Squared Error (Linear Regression):', metrics.mean_squared_error(y_test,y_pred,squared=False))\n",
        "    print('Mean Abs Error (linear Regression):', metrics.mean_absolute_error(y_test,y_pred))\n",
        "    print('R2 Score (Linear):',metrics.r2_score(y_test,y_pred))\n",
        "    print('mean y_pred (Linear)', np.mean((y_pred)))\n",
        "    y_pred_linear=y_pred\n",
        "    print(y_test)\n",
        "    #LinR=pd.DataFrame({'Actual Test': y_test, 'Predicted Linear': y_pred })\n",
        "    #LinR.to_csv('LinR.csv')\n",
        "    #np.savetxt('RMSE_Linear.txt',  [np.sqrt(metrics.mean_squared_error(y_test, y_pred))])\n",
        "    continue\n",
        "  if type=='lasso':\n",
        "    regressor=linear_model.Lasso(alpha=2/3, tol=0.1)\n",
        "    regressor.fit(X_train, y_train)\n",
        "    print(regressor.coef_)\n",
        "    y_pred = regressor.predict(X_test)\n",
        "    #y_pred=y_pred*data_std[-1]+data_mean[-1]  #uncomment when data is normalized\n",
        "    print('Root Mean Squared Error (Lasso Regression):', metrics.mean_squared_error(y_test,y_pred,squared=False))\n",
        "    print('Mean Abs Error (Lasso Regression):', metrics.mean_absolute_error(y_test,y_pred))\n",
        "    print('R2 Score (Lasso):',metrics.r2_score(y_test,y_pred))\n",
        "    print('mean y_pred (lasso)', np.mean((y_pred)))\n",
        "    y_pred_lasso = y_pred\n",
        "    print(y_test)\n",
        "    #LS=pd.DataFrame({'Actual Test': y_test, 'Predicted Linear': y_pred })\n",
        "    #LS.to_csv('LS.csv')\n",
        "    #np.savetxt('RMSE_Lasso.txt',  [np.sqrt(metrics.mean_squared_error(y_test, y_pred))])\n",
        "    continue\n",
        "\n",
        "  if type == 'GLM': # GLM cannot be run with normalized power, because then dependent variable becomes negative\n",
        "    exog, endog = sm.add_constant(X_train), y_train\n",
        "    mod = sm.GLM(endog,exog,family=sm.families.Gaussian(link=sm.families.links.log()))\n",
        "    res = mod.fit(maxiter=100)\n",
        "    with np.errstate(divide='ignore'):\n",
        "      yhat = res.predict(sm.add_constant(X_test))\n",
        "    sqared_diff_sensor = 0\n",
        "    for i in range(len(y_test)):\n",
        "      sqared_diff_sensor = sqared_diff_sensor + (y_test[i] - yhat[i])**2\n",
        "\n",
        "    RMSE_sensor = math.sqrt((sqared_diff_sensor)/len(y_test))\n",
        "   \n",
        "    #print(RMSE_sensor)\n",
        "    print('Root Mean Squared Error (GLM):', metrics.mean_squared_error(y_test,yhat,squared=False))\n",
        "    print('Mean Abs Error (GLM):', metrics.mean_absolute_error(y_test,yhat))\n",
        "    print('R2 Score (GLM):',metrics.r2_score(y_test,yhat))\n",
        "    print('mean y_pred (glm)', np.mean((yhat)))\n",
        "    print(y_test)\n",
        "\n",
        "    y_pred_glm = yhat\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data_mean [4.36176613e+04 8.45730576e+00 6.62704919e-03 4.58272116e-01\n",
            " 1.79107169e+02] data_std [2.88180099e+04 2.28682417e+00 6.50529032e+00 3.17041106e+00\n",
            " 9.70915596e+01]\n",
            "mean y_test 211.56334777607404\n",
            "Root Mean Squared Error (Linear Regression): 225.85071126457728\n",
            "Mean Abs Error (linear Regression): 211.54850078593552\n",
            "R2 Score (Linear): -7.10629266034579\n",
            "mean y_pred (Linear) 0.017573575307170373\n",
            "[331. 331. 333. ...   0.   0.   0.]\n",
            "[-0.  0.  0.  0.]\n",
            "Root Mean Squared Error (Lasso Regression): 225.94581821796817\n",
            "Mean Abs Error (Lasso Regression): 211.56334777607404\n",
            "R2 Score (Lasso): -7.1131213050077555\n",
            "mean y_pred (lasso) 6.281859915565045e-17\n",
            "[331. 331. 333. ...   0.   0.   0.]\n",
            "[331. 331. 333. ...   0.   0.   0.]\n",
            "Root Mean Squared Error (SVR Regression): 225.94354213060075\n",
            "Mean Abs Error (SVR Regression): 211.66208181394967\n",
            "R2 Score (SVR): -7.112957849184161\n",
            "mean y_pred (svr) -0.09738544494760219\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_f5d27734-b6d7-4b67-9ffe-b1c606f7ca4c\", \"predict_r1_sensor_ext.csv\", 539285)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkXft6cIGlr_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "774179e6-c6e6-4bd4-8a94-fd40a2756de9"
      },
      "source": [
        "#to download the predictions - no need to run if you don't want to download\n",
        "\n",
        "#d={'y_test':y_test,'watts_calc':y_watts_calc,'y_pred_linear':y_pred_linear,'y_pred_lasso':y_pred_lasso,'y_pred_svr':y_pred_svr,'y_pred_glm':y_pred_glm} #to be used with riders1 to 3, because they have watts_calc(strava feature in the data)\n",
        "#d={'y_test':y_test,'y_pred_linear':y_pred_linear,'y_pred_lasso':y_pred_lasso,'y_pred_svr':y_pred_svr,'y_pred_glm':y_pred_glm} # to be used with rider 4\n",
        "d={'y_test':y_test,'y_pred_linear':y_pred_linear,'y_pred_lasso':y_pred_lasso,'y_pred_svr':y_pred_svr} # uncomment when GLM is removed from the list above and data is normalized\n",
        "pred_df=pd.DataFrame(d)\n",
        "pred_df.to_csv('predict_r1_sensor_ext.csv')\n",
        "files.download('predict_r1_sensor_ext.csv')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_273031dd-bee2-4111-ae74-1427181edafc\", \"predict_r1_sensor_ext.csv\", 539285)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7Nu1hOjFClW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7ad86b09-643d-446b-82f4-e41b69e4adda"
      },
      "source": [
        "#do not use this: this was version 1 implementation for rider wise\n",
        "\n",
        "\n",
        "header_sensor_watts_new =[ 'cadence', 'temp', 'altitude', 'grade_smooth','distance',\n",
        "                        'weight_bike_rider_70', 'speed_from_sensor(m/s)', 'wind_resistance_sensor(N)', 'accel_sensor(m2/s)', 'watts' ]\n",
        "\n",
        "header_gps_watts_new = [ 'cadence',  'temp', 'altitude',   'grade_smooth', 'distance_calc(m)',\n",
        "                        'weight_bike_rider_70',  'speed_from_gps(m/s)',  'wind_resistance_gps(N)',   'accel_gps(m2/s)',   'watts']\n",
        "\n",
        "header_sensor_strava=[ 'cadence', 'temp', 'altitude', 'grade_smooth',  \n",
        "        'weight_bike_rider_70', 'speed_from_sensor(m/s)', 'wind_resistance_sensor(N)', 'accel_sensor(m2/s)', 'watts_calc' ]\n",
        "\n",
        "header_gps_strava=[   'cadence',  'temp', 'altitude',   'grade_smooth',\n",
        "        'weight_bike_rider_70',  'speed_from_gps(m/s)',  'wind_resistance_gps(N)',   'accel_gps(m2/s)',   'watts_calc']\n",
        "\n",
        "header_sensor_watts_all = ['moving', 'distance',  'heartrate', 'cadence','lat', 'lng', 'temp', 'altitude','weight_bike_rider_70',\n",
        "                      'speed_from_sensor(m/s)','wind_resistance_sensor(N)','accel_sensor(m2/s)','watts']\n",
        "\n",
        "header_sensor_minimal_new = ['distance','speed_from_sensor(m/s)','accel_sensor(m2/s)','grade_smooth','watts_calc','watts']#,'weight_bike_rider_80'\n",
        "header_gps_minimal_new = ['distance_calc(m)','speed_from_gps(m/s)','accel_gps(m2/s)','grade_smooth','weight_bike_rider_80','watts_calc', 'watts']\n",
        "\n",
        "header_sensor_extended_new = ['distance','speed_from_sensor(m/s)','accel_sensor(m2/s)','grade_smooth','weight_bike_rider_80','wind_resistance_sensor(N)',\n",
        "                              'temp','cadence','altitude','heartrate','watts_calc','watts']\n",
        "header_gps_extended_new = ['distance_calc(m)','speed_from_gps(m/s)','accel_gps(m2/s)','grade_smooth','weight_bike_rider_80','wind_resistance_gps(N)',\n",
        "                           'temp','cadence','altitude','heartrate','watts_calc','watts']\n",
        "\n",
        "new_files = glob.glob(\"//root//data//*.csv\")\n",
        "li1=[]\n",
        "lastdf=0\n",
        "for filename in new_files:\n",
        "    print('Importing...',filename)\n",
        "    df1=pd.read_csv(filename, index_col=None, header=0)\n",
        "    #df1[['cadence','altitude_smooth','grade_smooth','velocity_smooth','watts']].str.strip()\n",
        "    print('before drop',len(df1))\n",
        "    df1.replace(r\"^\\s*$\",np.nan,inplace=True, regex=True)\n",
        "    df1.replace(r\"^\\s*true$\",1,inplace=True, regex=True)\n",
        "    df1.replace(r\"^\\s*false$\",0,inplace=True, regex=True)\n",
        "    df1.dropna(axis=0,how='any',inplace=True)\n",
        "    print('after drop',len(df1))\n",
        "    lastdf=len(df1)\n",
        "    li1.append(df1)\n",
        "\n",
        "new_df = pd.concat(li1, axis=0, ignore_index=True)\n",
        "new_header = header_sensor_minimal_new\n",
        "new_df_data = new_df[new_header]\n",
        "features = new_df_data\n",
        "features\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Importing... //root//data/rider1_ride2_raw.csv\n",
            "before drop 13314\n",
            "after drop 13306\n",
            "Importing... //root//data/rider3_ride2_raw.csv\n",
            "before drop 14263\n",
            "after drop 14258\n",
            "Importing... //root//data/rider1_ride4_raw.csv\n",
            "before drop 6636\n",
            "after drop 6631\n",
            "Importing... //root//data/rider4_ride6_raw_old.csv\n",
            "before drop 7195\n",
            "after drop 7195\n",
            "Importing... //root//data/rider1_ride1_raw.csv\n",
            "before drop 14153\n",
            "after drop 13697\n",
            "Importing... //root//data/rider2_ride2_raw.csv\n",
            "before drop 9572\n",
            "after drop 9555\n",
            "Importing... //root//data/rider3_ride3_raw.csv\n",
            "before drop 12042\n",
            "after drop 12041\n",
            "Importing... //root//data/rider4_ride3_raw_old.csv\n",
            "before drop 14204\n",
            "after drop 14204\n",
            "Importing... //root//data/rider4_ride7_raw_old.csv\n",
            "before drop 8203\n",
            "after drop 8203\n",
            "Importing... //root//data/rider4_ride1_raw_old.csv\n",
            "before drop 4245\n",
            "after drop 4245\n",
            "Importing... //root//data/rider3_ride5_raw.csv\n",
            "before drop 8447\n",
            "after drop 8444\n",
            "Importing... //root//data/rider3_ride1_raw.csv\n",
            "before drop 4651\n",
            "after drop 4651\n",
            "Importing... //root//data/rider2_ride4_raw.csv\n",
            "before drop 4699\n",
            "after drop 4698\n",
            "Importing... //root//data/rider4_ride2_raw_old.csv\n",
            "before drop 7402\n",
            "after drop 7402\n",
            "Importing... //root//data/rider1_ride3_raw.csv\n",
            "before drop 2316\n",
            "after drop 2312\n",
            "Importing... //root//data/rider4_ride8_raw_old.csv\n",
            "before drop 7284\n",
            "after drop 7284\n",
            "Importing... //root//data/rider2_ride5_raw.csv\n",
            "before drop 4065\n",
            "after drop 4064\n",
            "Importing... //root//data/rider2_ride3_raw.csv\n",
            "before drop 7931\n",
            "after drop 7911\n",
            "Importing... //root//data/rider2_ride1_raw.csv\n",
            "before drop 3221\n",
            "after drop 3221\n",
            "Importing... //root//data/rider4_ride9_raw_old.csv\n",
            "before drop 14124\n",
            "after drop 14124\n",
            "Importing... //root//data/rider4_ride5_raw_old.csv\n",
            "before drop 8649\n",
            "after drop 8649\n",
            "Importing... //root//data/rider4_ride4_raw_old.csv\n",
            "before drop 8939\n",
            "after drop 8939\n",
            "Importing... //root//data/rider3_ride4_raw.csv\n",
            "before drop 7944\n",
            "after drop 7943\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>distance</th>\n",
              "      <th>speed_from_sensor(m/s)</th>\n",
              "      <th>accel_sensor(m2/s)</th>\n",
              "      <th>grade_smooth</th>\n",
              "      <th>watts_calc</th>\n",
              "      <th>watts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9.3</td>\n",
              "      <td>6.2</td>\n",
              "      <td>4.2</td>\n",
              "      <td>1.2</td>\n",
              "      <td>329.0</td>\n",
              "      <td>176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14.9</td>\n",
              "      <td>5.6</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17.8</td>\n",
              "      <td>2.9</td>\n",
              "      <td>-2.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24.0</td>\n",
              "      <td>6.2</td>\n",
              "      <td>3.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>271.0</td>\n",
              "      <td>181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30.3</td>\n",
              "      <td>6.3</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192972</th>\n",
              "      <td>63494.3</td>\n",
              "      <td>10.4</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-10.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192973</th>\n",
              "      <td>63503.6</td>\n",
              "      <td>9.3</td>\n",
              "      <td>-1.1</td>\n",
              "      <td>-11.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192974</th>\n",
              "      <td>63511.6</td>\n",
              "      <td>8.0</td>\n",
              "      <td>-1.3</td>\n",
              "      <td>-13.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192975</th>\n",
              "      <td>63518.0</td>\n",
              "      <td>6.4</td>\n",
              "      <td>-1.6</td>\n",
              "      <td>-15.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192976</th>\n",
              "      <td>63522.1</td>\n",
              "      <td>4.1</td>\n",
              "      <td>-2.3</td>\n",
              "      <td>-17.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>192977 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        distance  speed_from_sensor(m/s)  ...  watts_calc   watts\n",
              "0            9.3                     6.2  ...       329.0     176\n",
              "1           14.9                     5.6  ...         8.0     201\n",
              "2           17.8                     2.9  ...         0.0     190\n",
              "3           24.0                     6.2  ...       271.0     181\n",
              "4           30.3                     6.3  ...        68.0     198\n",
              "...          ...                     ...  ...         ...     ...\n",
              "192972   63494.3                    10.4  ...         0.0       0\n",
              "192973   63503.6                     9.3  ...         0.0       0\n",
              "192974   63511.6                     8.0  ...         0.0       0\n",
              "192975   63518.0                     6.4  ...         0.0       0\n",
              "192976   63522.1                     4.1  ...         0.0       0\n",
              "\n",
              "[192977 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    }
  ]
}
